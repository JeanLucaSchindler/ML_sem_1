{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genX(n):\n",
    "    np.random.seed(7)\n",
    "    x1 = np.random.uniform(-5, 5, n)\n",
    "    x2 = np.random.uniform(-2, 2, n)\n",
    "    x0 = np.ones(n)\n",
    "    df = pd.DataFrame({'x0': x0, 'x1': x1, 'x2': x2})\n",
    "    return x0, x1, x2, df\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(n):\n",
    "    np.random.seed(7)\n",
    "    x0, x1, x2, x_dataframe = genX(n)\n",
    "\n",
    "    linear_y = 3 * x0 + 1 * x1 - 2 * x2 + np.random.normal(0, 0.05, n)\n",
    "\n",
    "    y = np.random.binomial(1, sigmoid(linear_y))\n",
    "\n",
    "    return x_dataframe, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_row(row, coefficients):\n",
    "\n",
    "    pred_terms = np.multiply(row, coefficients)\n",
    "    yhat = np.sum(pred_terms)\n",
    "    return 1 / (1 + np.exp(-yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, yhat):\n",
    "    return np.mean((y - yhat)**2)\n",
    "\n",
    "def nll(y, yhat):\n",
    "    return -np.mean(y * np.log(yhat) + (1 - y) * np.log(1 - yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "X, y = gen_data(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_model():\n",
    "    print('True model:')\n",
    "    y_pred = np.zeros(n)\n",
    "\n",
    "    for row in range(n):\n",
    "        y_pred[row] = predict_row(np.array(X.iloc[row]), np.array([3,1,-2]))\n",
    "\n",
    "    print(f'MSE: {mse(y, y_pred)}')\n",
    "    print(f'NLL: {nll(y, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2996565695865238\n",
      "NLL: 0.9081213170722178\n",
      "\n",
      "True model:\n",
      "MSE: 0.06831581573421616\n",
      "NLL: 0.21844118029674345\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.zeros(n)\n",
    "\n",
    "for row in range(n):\n",
    "    y_pred[row] = predict_row(np.array(X.iloc[row]), np.array([0,0.5,1]))\n",
    "\n",
    "print(f'MSE: {mse(y, y_pred)}')\n",
    "print(f'NLL: {nll(y, y_pred)}')\n",
    "\n",
    "print()\n",
    "true_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial derivative of the NLL with respect to a coefficient ($ \\beta_k\\ $) is given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{NLL}}{\\partial \\beta_k} = (\\hat{y} - y) \\cdot x_k\n",
    "$$\n",
    "\n",
    "\n",
    "This derivative indicates how much $ \\beta_k  $ should change to reduce the error.\n",
    "\n",
    "##### Update Rule:\n",
    "Using the learning rate ($\\eta$), the update rule for the coefficients is:\n",
    "\n",
    "$$\n",
    "\\beta_k \\gets \\beta_k - \\eta \\cdot \\frac{\\partial \\text{NLL}}{\\partial \\beta_k}\n",
    "$$\n",
    "\n",
    "Substituting the derivative:\n",
    "\n",
    "$$\n",
    "\\beta_k \\gets \\beta_k - \\eta \\cdot (\\hat{y} - y) \\cdot x_k\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sake of testing\n",
    "i = 1\n",
    "coefs = np.zeros(3) # (beta_0,beta_1,beta_2)\n",
    "l_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the outcome for row i\n",
    "yhat_i = predict_row(np.array(X.iloc[i]), coefs)\n",
    "\n",
    "# Update each coefficient\n",
    "for k in range(len(coefs)):\n",
    "    coefs[k] = coefs[k] - l_rate * (yhat_i - y[i]) * X.iloc[i, k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.005     , 0.01399594, 0.00052306])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.91031708,  1.06186663, -1.7851285 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = np.zeros(3) # (beta_0,beta_1,beta_2)\n",
    "l_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "for _ in range(epochs):\n",
    "    i = np.arange(n)\n",
    "    np.random.shuffle(i)\n",
    "    for index in i:\n",
    "        # Predict the outcome for row i\n",
    "        yhat_i = predict_row(np.array(X.iloc[index]), coefs)\n",
    "\n",
    "        # Update each coefficient\n",
    "        for k in range(len(coefs)):\n",
    "            coefs[k] = coefs[k] - l_rate * (yhat_i - y[index]) * X.iloc[index, k]\n",
    "\n",
    "coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert our estimator into a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X , y, l_rate, epochs):\n",
    "    n = X.shape[0]\n",
    "    coefs = np.zeros(X.shape[1]) # (beta_0,beta_1,beta_2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        yhats = np.zeros(n)\n",
    "        i = np.arange(n)\n",
    "        np.random.shuffle(i)\n",
    "        for index in i:\n",
    "            # Predict the outcome for row i\n",
    "            yhat_i = predict_row(X[index, :], coefs)\n",
    "            yhats[index] = yhat_i\n",
    "\n",
    "            # Update each coefficient\n",
    "            for k in range(len(coefs)):\n",
    "                coefs[k] = coefs[k] - l_rate * (yhat_i - y[index]) * X[index, k]\n",
    "\n",
    "        print()\n",
    "        print(f'Epoch: {epoch+1}')\n",
    "        print(f'MSE: {mse(y, yhats)}')\n",
    "        print(f'NLL: {nll(y, yhats)}')\n",
    "\n",
    "    return coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "MSE: 0.11263013736413799\n",
      "NLL: 0.36802017870647363\n",
      "\n",
      "Epoch: 2\n",
      "MSE: 0.07754586065326635\n",
      "NLL: 0.26249982704373986\n",
      "\n",
      "Epoch: 3\n",
      "MSE: 0.072276854916161\n",
      "NLL: 0.23989746755172156\n",
      "\n",
      "Epoch: 4\n",
      "MSE: 0.06994573356201068\n",
      "NLL: 0.2298914150944504\n",
      "\n",
      "Epoch: 5\n",
      "MSE: 0.06904666369499703\n",
      "NLL: 0.22505467755652445\n",
      "\n",
      "Epoch: 6\n",
      "MSE: 0.06894033514491528\n",
      "NLL: 0.22231721138972438\n",
      "\n",
      "Epoch: 7\n",
      "MSE: 0.06888994071212937\n",
      "NLL: 0.22156562895248452\n",
      "\n",
      "Epoch: 8\n",
      "MSE: 0.06866697562401922\n",
      "NLL: 0.22059103779985192\n",
      "\n",
      "Epoch: 9\n",
      "MSE: 0.06855474975977552\n",
      "NLL: 0.21984699834999005\n",
      "\n",
      "Epoch: 10\n",
      "MSE: 0.06899042192323145\n",
      "NLL: 0.21987740920681068\n",
      "\n",
      "Epoch: 11\n",
      "MSE: 0.0677493272336344\n",
      "NLL: 0.21810797552721506\n",
      "\n",
      "Epoch: 12\n",
      "MSE: 0.0685432797683098\n",
      "NLL: 0.218805213067784\n",
      "\n",
      "Epoch: 13\n",
      "MSE: 0.06860037734506745\n",
      "NLL: 0.21806116793966077\n",
      "\n",
      "Epoch: 14\n",
      "MSE: 0.06866977681666168\n",
      "NLL: 0.21877129509944485\n",
      "\n",
      "Epoch: 15\n",
      "MSE: 0.06816273347709582\n",
      "NLL: 0.217211367242172\n",
      "\n",
      "Epoch: 16\n",
      "MSE: 0.0684131254195128\n",
      "NLL: 0.21735741958602228\n",
      "\n",
      "Epoch: 17\n",
      "MSE: 0.06818689318575598\n",
      "NLL: 0.21669956095425771\n",
      "\n",
      "Epoch: 18\n",
      "MSE: 0.06890837825973724\n",
      "NLL: 0.21930045380697907\n",
      "\n",
      "Epoch: 19\n",
      "MSE: 0.06853151417420766\n",
      "NLL: 0.21788865163918153\n",
      "\n",
      "Epoch: 20\n",
      "MSE: 0.06865871886911938\n",
      "NLL: 0.21841609818971489\n",
      "\n",
      "Epoch: 21\n",
      "MSE: 0.06866035484186395\n",
      "NLL: 0.21806625723087264\n",
      "\n",
      "Epoch: 22\n",
      "MSE: 0.06861041513283013\n",
      "NLL: 0.21832438036996052\n",
      "\n",
      "Epoch: 23\n",
      "MSE: 0.06871406900968682\n",
      "NLL: 0.21744416943577732\n",
      "\n",
      "Epoch: 24\n",
      "MSE: 0.06875847022278941\n",
      "NLL: 0.21839870622569652\n",
      "\n",
      "Epoch: 25\n",
      "MSE: 0.06862348967308288\n",
      "NLL: 0.21814258655673677\n",
      "\n",
      "Epoch: 26\n",
      "MSE: 0.06869711183021446\n",
      "NLL: 0.21821416658155032\n",
      "\n",
      "Epoch: 27\n",
      "MSE: 0.06843783623504666\n",
      "NLL: 0.2180511143303384\n",
      "\n",
      "Epoch: 28\n",
      "MSE: 0.0685825481185761\n",
      "NLL: 0.21815309890659318\n",
      "\n",
      "Epoch: 29\n",
      "MSE: 0.06888758647810808\n",
      "NLL: 0.2182433173426989\n",
      "\n",
      "Epoch: 30\n",
      "MSE: 0.06818466512223705\n",
      "NLL: 0.21726822863335343\n",
      "\n",
      "Epoch: 31\n",
      "MSE: 0.06816943260882286\n",
      "NLL: 0.2177698943501009\n",
      "\n",
      "Epoch: 32\n",
      "MSE: 0.0688622072865413\n",
      "NLL: 0.2182567907799255\n",
      "\n",
      "Epoch: 33\n",
      "MSE: 0.06871595425055695\n",
      "NLL: 0.21848638358080089\n",
      "\n",
      "Epoch: 34\n",
      "MSE: 0.06859106472813967\n",
      "NLL: 0.21728405376949753\n",
      "\n",
      "Epoch: 35\n",
      "MSE: 0.06905216448129434\n",
      "NLL: 0.21881520030232865\n",
      "\n",
      "Epoch: 36\n",
      "MSE: 0.06873207371330757\n",
      "NLL: 0.21799576855623684\n",
      "\n",
      "Epoch: 37\n",
      "MSE: 0.06799886207025142\n",
      "NLL: 0.21637743046187244\n",
      "\n",
      "Epoch: 38\n",
      "MSE: 0.06869838684089828\n",
      "NLL: 0.21860773227030475\n",
      "\n",
      "Epoch: 39\n",
      "MSE: 0.06873301080617782\n",
      "NLL: 0.2185850126917293\n",
      "\n",
      "Epoch: 40\n",
      "MSE: 0.0687913016666339\n",
      "NLL: 0.2183910589213964\n",
      "\n",
      "Epoch: 41\n",
      "MSE: 0.06859830284645696\n",
      "NLL: 0.21728672480546798\n",
      "\n",
      "Epoch: 42\n",
      "MSE: 0.06861996648135807\n",
      "NLL: 0.21796871144638935\n",
      "\n",
      "Epoch: 43\n",
      "MSE: 0.06840422047167163\n",
      "NLL: 0.21773080104966858\n",
      "\n",
      "Epoch: 44\n",
      "MSE: 0.06837440976143498\n",
      "NLL: 0.2177186542181869\n",
      "\n",
      "Epoch: 45\n",
      "MSE: 0.06827434568705405\n",
      "NLL: 0.2173858382210134\n",
      "\n",
      "Epoch: 46\n",
      "MSE: 0.06874062080192829\n",
      "NLL: 0.21817212173379194\n",
      "\n",
      "Epoch: 47\n",
      "MSE: 0.06830783303100356\n",
      "NLL: 0.21690262305394686\n",
      "\n",
      "Epoch: 48\n",
      "MSE: 0.06776589243380475\n",
      "NLL: 0.21662524490732915\n",
      "\n",
      "Epoch: 49\n",
      "MSE: 0.06832768301791316\n",
      "NLL: 0.21753186813776923\n",
      "\n",
      "Epoch: 50\n",
      "MSE: 0.06867362485549278\n",
      "NLL: 0.2183197895562127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.31964693,  1.11147701, -1.99262977])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = train(np.array(X), y, 0.01, 50)\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[-0.02595394  1.11737484 -1.93152413]]\n",
      "Intercept: [3.23600159]\n"
     ]
    }
   ],
   "source": [
    "# compare to ligistic regression package\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "\n",
    "print(f'Coefficients: {clf.coef_}')\n",
    "\n",
    "print(f'Intercept: {clf.intercept_}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
